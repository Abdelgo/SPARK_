{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733d27e2-aebf-4aa5-b934-4df2010a1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a179cea2-08ec-4ddd-a980-d7b1b0b9281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thesparkapp\n",
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.43.42:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>thesparkapp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x114021890>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"thesparkapp\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(spark.sparkContext.appName)\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fe161d8-6ad6-49bb-83f2-76626781d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = spark.read.csv('nyc_air_bnb.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d4e9263-8c2d-4aa0-96d3-304d1bd39a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- host_id: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- neighbourhood_group: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- minimum_nights: string (nullable = true)\n",
      " |-- number_of_reviews: string (nullable = true)\n",
      " |-- last_review: string (nullable = true)\n",
      " |-- reviews_per_month: string (nullable = true)\n",
      " |-- calculated_host_listings_count: string (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnb.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e68d44-5539-4f68-8ff1-057ab6d6abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e121a9-3f8e-4cbd-b779-763503f33237",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73cb7295-cd02-4eae-944c-ef8e0a9df798",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb.createOrReplaceTempView(\"Tempview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e49b2ce-2d3c-4459-8603-d2e8239b1967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|price|minimum_nights|\n",
      "+-----+--------------+\n",
      "|  149|             1|\n",
      "|  225|             1|\n",
      "|  150|             3|\n",
      "|   89|             1|\n",
      "|   80|            10|\n",
      "|  200|             3|\n",
      "|   60|            45|\n",
      "|   79|             2|\n",
      "|   79|             2|\n",
      "|  150|             1|\n",
      "|  135|             5|\n",
      "|   85|             2|\n",
      "|   89|             4|\n",
      "|   85|             2|\n",
      "|  120|            90|\n",
      "|  140|             2|\n",
      "|  215|             2|\n",
      "|  140|             1|\n",
      "|   99|             3|\n",
      "|  190|             7|\n",
      "+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select price,minimum_nights from Tempview\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6776feb9-318d-42c5-94af-8d05024964ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   49079|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49079, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb.count(), spark.sql(\"Select count(*) from Tempview\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f8e5d2e-7223-42a4-82ae-b4d563423a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"Select price,minimum_nights from Tempview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff908eb2-4d6f-4a89-abd8-9be146c6a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price', 'minimum_nights']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37180259-e548-4d98-a9fd-5486cc98f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str=['{\"price\":\"0\", \"minimum_nights\":\"1000\"}',\n",
    "         '{\"price\":\"1000\", \"minimum_nights\":\"0\"}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f589fdb-6d9e-4bfa-a11e-3c0a77552e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "newlineRdd = spark.sparkContext.parallelize(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "075029e6-08b1-4758-ae85-a4c1c9cc00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "morelines = spark.read.json(newlineRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "409a4637-8320-46f4-bde2-cc403f5822e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ddfe826-6cb2-446e-8ccc-396c23c218d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "morelines = morelines.select(col(\"price\"),col(\"minimum_nights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ae97c3c-366b-4a27-bfa9-759234dd3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = df.union(morelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3774e13-8ad0-4cdf-8a89-cd1ba5cc64b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|    price| minimum_nights|\n",
      "+---------+---------------+\n",
      "|        0|              4|\n",
      "|        0|              2|\n",
      "|        0|              2|\n",
      "|        0|              2|\n",
      "|        0|              5|\n",
      "|        0|              1|\n",
      "|        0|              1|\n",
      "|        0|              1|\n",
      "|        0|              3|\n",
      "|        0|             30|\n",
      "|        0|             30|\n",
      "|-73.99986|   Private room|\n",
      "|-74.00828|Entire home/apt|\n",
      "|        0|           1000|\n",
      "+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alldata.filter(\"price < 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f156d4c-dcb4-4785-ae64-9e560b7be220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|price|minimum_nights|\n",
      "+-----+--------------+\n",
      "| 1000|             0|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alldata.filter(\"price > 999 and minimum_nights < 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed0e42-65ef-4533-9858-73ac63ffd042",
   "metadata": {},
   "source": [
    "## Reading files with spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fccf880e-3bb2-4bc8-9ffd-ed87df416fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = spark.sql(\"select * from format.`filepath.format`\")\n",
    "#df2 = spark.sql(\"select * from parquet.`filepath.parquet`\")\n",
    "df2 = spark.sql(\"select * from csv.`nyc_air_bnb.csv`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b293fc4-d3c6-4e6b-8246-de5c14e3de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cc36e-e58d-42b4-a2c8-4913ad61bab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a834462-e7eb-4f60-9a0a-917c0dce2d2c",
   "metadata": {},
   "source": [
    "# Load & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "503d236a-5423-4708-82eb-de162c0cf497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.load('nyc_air_bnb.csv',format=\"csv\")\n",
    "df1 = spark.read.option(\"header\",True).csv('nyc_air_bnb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b440f2d-d42e-4a9b-abd5-04cbfdedeed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adeb55e-bacc-42e6-8025-48b79b747d35",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ed6cb-62b1-4d4b-8dc1-b0419ee21964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.write.save(path=\"path\",format=\"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b246d7-5d3c-482d-bc1a-16a0f24ead6d",
   "metadata": {},
   "source": [
    "## SaveMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7a6e1c0-9a94-4404-9a95-637895c2cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modes : append, error, ignore, overwrite\n",
    "airbnb.write.mode(\"error\").json(\"theairbnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7a15301-77ea-410e-98a2-917e495ca60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.json(\"theairbnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aacfc3f2-2fa0-46fd-9dc9-c3d4f9925a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- availability_365: long (nullable = true)\n",
      " |-- calculated_host_listings_count: string (nullable = true)\n",
      " |-- host_id: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- last_review: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- minimum_nights: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- neighbourhood_group: string (nullable = true)\n",
      " |-- number_of_reviews: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- reviews_per_month: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a89b8f-1f1d-4b56-bb3f-9b8d13b6c023",
   "metadata": {},
   "source": [
    "## Persistent Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53d74fa9-2bf9-4334-b6f1-ec4e535d317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb.write.saveAsTable(\"airbnbTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa3e28a3-5d30-4e96-b5c9-d697c9938ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------+---------+-------------------+-------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "|  id|                name|host_id|host_name|neighbourhood_group|neighbourhood|latitude|longitude|      room_type|price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|\n",
      "+----+--------------------+-------+---------+-------------------+-------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "|2539|Clean & quiet apt...|   2787|     John|           Brooklyn|   Kensington|40.64749|-73.97237|   Private room|  149|             1|                9| 2018-10-19|             0.21|                             6|             365|\n",
      "|2595|Skylit Midtown Ca...|   2845| Jennifer|          Manhattan|      Midtown|40.75362|-73.98377|Entire home/apt|  225|             1|               45| 2019-05-21|             0.38|                             2|             355|\n",
      "+----+--------------------+-------+---------+-------------------+-------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from airbnbTable\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83adc64c-b6db-4e5a-802d-4e943259c56c",
   "metadata": {},
   "source": [
    "## Partitionning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc99dc3-6b9c-4bdc-9d08-6ffa3a4a61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb.write.partitionBy(\"columnname\").saveAsTable(\"airbnbPartitions\")\n",
    "spark.sql(\"show partitions airbnbPartitions\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f767a5-23f0-449a-a699-b5f46ad26e9b",
   "metadata": {},
   "source": [
    "# Global Temporary View\n",
    "Temporary views in Spark SQL are session-scoped and will disappear if the session that creates it terminates. If you want to have a temporary view that is shared among all sessions and keep alive until the Spark application terminates, you can create a global temporary view. Global temporary view is tied to a system preserved database global_temp, and we must use the qualified name to refer it, e.g. SELECT * FROM global_temp.view1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5013daf7-2dad-46e4-81b1-a42aa9534b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb.createGlobalTempView(\"globairbnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b73cab2-b503-4e7e-9fc5-adcd188c905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------+---------+-------------------+-------------+--------+---------+------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "|  id|                name|host_id|host_name|neighbourhood_group|neighbourhood|latitude|longitude|   room_type|price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|\n",
      "+----+--------------------+-------+---------+-------------------+-------------+--------+---------+------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "|2539|Clean & quiet apt...|   2787|     John|           Brooklyn|   Kensington|40.64749|-73.97237|Private room|  149|             1|                9| 2018-10-19|             0.21|                             6|             365|\n",
      "+----+--------------------+-------+---------+-------------------+-------------+--------+---------+------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.newSession().sql(\"SELECT * FROM global_temp.globairbnb\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b360a-406a-43b6-8203-fa468f7dafa8",
   "metadata": {},
   "source": [
    "# SCALA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1514d-a11b-41b3-aa11-070c0b0924d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Nameclass(age:Integer, gender:String)\n",
    "val data = spark.read.csv(\"filepath\").as[Nameclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "931311a6-a65b-4eb7-9f19-98d5321ca91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1ccc6-8ba1-40ce-b689-62548a54ce33",
   "metadata": {},
   "source": [
    "# Broadcast functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "410ba158-587c-4973-90b5-47f4561407f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1af7514e-bcd5-4ab5-9d7b-0697174d3f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thesparkapp\n",
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.43.42:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>thesparkapp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1141d4fd0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"thesparkapp\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(spark.sparkContext.appName)\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "881afa03-23ad-41d8-9fc6-7d316c4db9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris= spark.read.csv('iris.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ffe26870-c14d-4432-875a-a7a418b4155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11ef239e-c541-4ed6-9feb-277d677c328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8ccf334-049d-402c-8151-df6d9c8c1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"species\",\"string\").add(\"Id\",\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da850f2b-ddf3-4103-aff6-7b08aa777f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speciestable = spark.createDataFrame([(\"setosa\",1),(\"versicolor\",2),(\"virginica\",3)],schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43200b61-43c7-4d7f-836a-fb4d0e0ab147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|   species| Id|\n",
      "+----------+---+\n",
      "|    setosa|  1|\n",
      "|versicolor|  2|\n",
      "| virginica|  3|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speciestable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e8c49074-2337-4741-8486-fba065f978a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "irisjoin = iris.join(speciestable,on='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59f70c58-9f71-40f3-8cdb-faab2455fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c6a78f49-699a-46af-8506-419ea960979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+------------+-----------+---+\n",
      "|  species|sepal_length|sepal_width|petal_length|petal_width| Id|\n",
      "+---------+------------+-----------+------------+-----------+---+\n",
      "|virginica|         5.9|        3.0|         5.1|        1.8|  3|\n",
      "|virginica|         6.2|        3.4|         5.4|        2.3|  3|\n",
      "+---------+------------+-----------+------------+-----------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisjoin.filter(col(\"species\")==\"virginica\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e4b08b33-41b6-408e-835d-60b495d94af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----------+------------+-----------+---+\n",
      "|species|sepal_length|sepal_width|petal_length|petal_width| Id|\n",
      "+-------+------------+-----------+------------+-----------+---+\n",
      "| setosa|         5.0|        3.3|         1.4|        0.2|  1|\n",
      "| setosa|         5.3|        3.7|         1.5|        0.2|  1|\n",
      "+-------+------------+-----------+------------+-----------+---+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+------------+-----------+------------+-----------+---+\n",
      "|   species|sepal_length|sepal_width|petal_length|petal_width| Id|\n",
      "+----------+------------+-----------+------------+-----------+---+\n",
      "|versicolor|         5.7|        2.8|         4.1|        1.3|  2|\n",
      "|versicolor|         5.1|        2.5|         3.0|        1.1|  2|\n",
      "+----------+------------+-----------+------------+-----------+---+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------+------------+-----------+------------+-----------+---+\n",
      "|  species|sepal_length|sepal_width|petal_length|petal_width| Id|\n",
      "+---------+------------+-----------+------------+-----------+---+\n",
      "|virginica|         5.9|        3.0|         5.1|        1.8|  3|\n",
      "|virginica|         6.2|        3.4|         5.4|        2.3|  3|\n",
      "+---------+------------+-----------+------------+-----------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in speciestable.select(col(\"species\")).toPandas()[\"species\"].unique():\n",
    "    irisjoin.filter(col(\"species\")==i).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9b25a8a-2c9c-438c-b54a-3e750e06f9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speciestable.select(col(\"species\")).toPandas()[\"species\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f898828-6fa0-45f8-a646-597dace742d7",
   "metadata": {},
   "source": [
    "### to add broadcast functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2f264718-7565-486d-a8b3-50672b9913c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64d7299f-5adc-4f3c-b68b-c9120a2309b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "speciestable = broadcast(spark.createDataFrame([(\"setosa\",1),(\"versicolor\",2),(\"virginica\",3)],schema=schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f9bc8fc8-17f7-44cf-853a-3f72659615b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "irisjoin = iris.join(speciestable,on='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e372abc-7b4e-4d18-a6bf-30022745b4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----------+------------+-----------+---+\n",
      "|species|sepal_length|sepal_width|petal_length|petal_width| Id|\n",
      "+-------+------------+-----------+------------+-----------+---+\n",
      "| setosa|         5.1|        3.5|         1.4|        0.2|  1|\n",
      "| setosa|         4.9|        3.0|         1.4|        0.2|  1|\n",
      "| setosa|         4.7|        3.2|         1.3|        0.2|  1|\n",
      "| setosa|         4.6|        3.1|         1.5|        0.2|  1|\n",
      "| setosa|         5.0|        3.6|         1.4|        0.2|  1|\n",
      "| setosa|         5.4|        3.9|         1.7|        0.4|  1|\n",
      "| setosa|         4.6|        3.4|         1.4|        0.3|  1|\n",
      "| setosa|         5.0|        3.4|         1.5|        0.2|  1|\n",
      "| setosa|         4.4|        2.9|         1.4|        0.2|  1|\n",
      "| setosa|         4.9|        3.1|         1.5|        0.1|  1|\n",
      "| setosa|         5.4|        3.7|         1.5|        0.2|  1|\n",
      "| setosa|         4.8|        3.4|         1.6|        0.2|  1|\n",
      "| setosa|         4.8|        3.0|         1.4|        0.1|  1|\n",
      "| setosa|         4.3|        3.0|         1.1|        0.1|  1|\n",
      "| setosa|         5.8|        4.0|         1.2|        0.2|  1|\n",
      "| setosa|         5.7|        4.4|         1.5|        0.4|  1|\n",
      "| setosa|         5.4|        3.9|         1.3|        0.4|  1|\n",
      "| setosa|         5.1|        3.5|         1.4|        0.3|  1|\n",
      "| setosa|         5.7|        3.8|         1.7|        0.3|  1|\n",
      "| setosa|         5.1|        3.8|         1.5|        0.3|  1|\n",
      "+-------+------------+-----------+------------+-----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisjoin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2a8f0504-2241-43f0-b1af-58cb5040bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Project [species#1280, sepal_length#1276, sepal_width#1277, petal_length#1278, petal_width#1279, Id#1574]\n",
      "+- *(2) BroadcastHashJoin [species#1280], [species#1573], Inner, BuildRight\n",
      "   :- *(2) Project [sepal_length#1276, sepal_width#1277, petal_length#1278, petal_width#1279, species#1280]\n",
      "   :  +- *(2) Filter isnotnull(species#1280)\n",
      "   :     +- FileScan csv [sepal_length#1276,sepal_width#1277,petal_length#1278,petal_width#1279,species#1280] Batched: false, DataFilters: [isnotnull(species#1280)], Format: CSV, Location: InMemoryFileIndex[file:/Users/livai/Desktop/CAPITAL/SPARK/iris.csv], PartitionFilters: [], PushedFilters: [IsNotNull(species)], ReadSchema: struct<sepal_length:double,sepal_width:double,petal_length:double,petal_width:double,species:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false])), [id=#1027]\n",
      "      +- *(1) Filter isnotnull(species#1573)\n",
      "         +- *(1) Scan ExistingRDD[species#1573,Id#1574]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisjoin.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c5378e00-3fa5-439b-9bbc-1af28f3f54fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner,Buffer(species))\n",
      ":- Relation[sepal_length#1276,sepal_width#1277,petal_length#1278,petal_width#1279,species#1280] csv\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- LogicalRDD [species#1573, Id#1574], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "species: string, sepal_length: double, sepal_width: double, petal_length: double, petal_width: double, Id: int\n",
      "Project [species#1280, sepal_length#1276, sepal_width#1277, petal_length#1278, petal_width#1279, Id#1574]\n",
      "+- Join Inner, (species#1280 = species#1573)\n",
      "   :- Relation[sepal_length#1276,sepal_width#1277,petal_length#1278,petal_width#1279,species#1280] csv\n",
      "   +- ResolvedHint (strategy=broadcast)\n",
      "      +- LogicalRDD [species#1573, Id#1574], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [species#1280, sepal_length#1276, sepal_width#1277, petal_length#1278, petal_width#1279, Id#1574]\n",
      "+- Join Inner, (species#1280 = species#1573), rightHint=(strategy=broadcast)\n",
      "   :- Filter isnotnull(species#1280)\n",
      "   :  +- Relation[sepal_length#1276,sepal_width#1277,petal_length#1278,petal_width#1279,species#1280] csv\n",
      "   +- Filter isnotnull(species#1573)\n",
      "      +- LogicalRDD [species#1573, Id#1574], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Project [species#1280, sepal_length#1276, sepal_width#1277, petal_length#1278, petal_width#1279, Id#1574]\n",
      "+- *(2) BroadcastHashJoin [species#1280], [species#1573], Inner, BuildRight\n",
      "   :- *(2) Project [sepal_length#1276, sepal_width#1277, petal_length#1278, petal_width#1279, species#1280]\n",
      "   :  +- *(2) Filter isnotnull(species#1280)\n",
      "   :     +- FileScan csv [sepal_length#1276,sepal_width#1277,petal_length#1278,petal_width#1279,species#1280] Batched: false, DataFilters: [isnotnull(species#1280)], Format: CSV, Location: InMemoryFileIndex[file:/Users/livai/Desktop/CAPITAL/SPARK/iris.csv], PartitionFilters: [], PushedFilters: [IsNotNull(species)], ReadSchema: struct<sepal_length:double,sepal_width:double,petal_length:double,petal_width:double,species:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false])), [id=#1027]\n",
      "      +- *(1) Filter isnotnull(species#1573)\n",
      "         +- *(1) Scan ExistingRDD[species#1573,Id#1574]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisjoin.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25bf60-067c-4165-bab9-dae04d6db6ff",
   "metadata": {},
   "source": [
    "```{python}\n",
    "irisjoin = iris.join(speciestable,on='species')\n",
    "irisjoin.explain()\n",
    "irisjoin.explain(extended=True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e2927-6b56-4599-bab8-70270efa9050",
   "metadata": {},
   "source": [
    "```python\n",
    "x = 'hello, python world!'\n",
    "print(x.split(' '))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fbdf89c1-3b5d-49fb-bcbd-208484e5b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff3f49-c47a-4e83-a9a6-3f03c2e7862e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Bigdata]",
   "language": "python",
   "name": "conda-env-Bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
